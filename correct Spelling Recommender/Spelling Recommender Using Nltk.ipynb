{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accordantly', 'accorder', 'according', 'accordingly', 'accordion']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = nltk.corpus.words.words()\n",
    "dictionary[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Distance\n",
    "\n",
    "<img src=\"jaccard.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We assumed that in first letter of misspelled word is right in correct spelled word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngrams=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_0(text):\n",
    "    \n",
    "    ans0 = []\n",
    "    \n",
    "    #print(text[0])\n",
    "    total_words = [w for w in dictionary if text[0] == w[0]]\n",
    "    \n",
    "    #print(total_words)\n",
    "    \n",
    "    jaccard_dist = [jaccard_distance(set(ngrams(text,n=3)),set(ngrams(w,n=3))) for w in total_words]\n",
    "    \n",
    "    #print(jaccard_dist)\n",
    "    \n",
    "    min_dist = min(jaccard_dist)\n",
    "    \n",
    "    ans0.append(total_words[jaccard_dist.index(min_dist)])\n",
    "    \n",
    "    return ans0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean']\n",
      "['validate']\n",
      "['indecence']\n",
      "['corpulent']\n",
      "['shieling']\n",
      "['recommender']\n"
     ]
    }
   ],
   "source": [
    "text = ['meano','validrate','incendenece','cormulent','spleling','reccomender']\n",
    "\n",
    "for t in text:\n",
    "    print(Model_0(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngram =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(text):\n",
    "    \n",
    "    ans = []\n",
    "    \n",
    "    #print(text[0])\n",
    "    total_words = [w for w in dictionary if text[0] == w[0]]\n",
    "    \n",
    "    #print(total_words)\n",
    "    \n",
    "    jaccard_dist = [jaccard_distance(set(ngrams(text,n=3)),set(ngrams(w,n=3))) for w in total_words]\n",
    "    \n",
    "    #print(jaccard_dist)\n",
    "    \n",
    "    min_dist = min(jaccard_dist)\n",
    "    \n",
    "    ans.append(total_words[jaccard_dist.index(min_dist)])\n",
    "    \n",
    "    return ans   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean']\n",
      "['validate']\n",
      "['indecence']\n",
      "['corpulent']\n",
      "['shieling']\n",
      "['recommender']\n"
     ]
    }
   ],
   "source": [
    "text = ['meano','validrate','incendenece','cormulent','spleling','reccomender']\n",
    "\n",
    "for t in text:\n",
    "    print(Model(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngram = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_2(text):\n",
    "    \n",
    "    ans2 = []\n",
    "    \n",
    "    #print(text[0])\n",
    "    total_words = [w for w in dictionary if text[0] == w[0]]\n",
    "    \n",
    "    #print(total_words)\n",
    "    \n",
    "    jaccard_dist = [jaccard_distance(set(ngrams(text,n=4)),set(ngrams(w,n=4))) for w in total_words]\n",
    "    \n",
    "    #print(jaccard_dist)\n",
    "    \n",
    "    min_dist = min(jaccard_dist)\n",
    "    \n",
    "    ans2.append(total_words[jaccard_dist.index(min_dist)])\n",
    "    \n",
    "    return ans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean']\n",
      "['valid']\n",
      "['incendiary']\n",
      "['cormus']\n",
      "['shieling']\n",
      "['recco']\n"
     ]
    }
   ],
   "source": [
    "text = ['meano','validrate','incendenece','cormulent','spleling','reccomender']\n",
    "\n",
    "for t in text:\n",
    "    print(Model_2(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "### Edit Distance\n",
    "\n",
    "<img src=\"index.png\">\n",
    "\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_3(text):\n",
    "    \n",
    "    ans3 = []\n",
    "    \n",
    "    #print(text[0])\n",
    "    total_words = [w for w in dictionary if text[0] == w[0]]\n",
    "    \n",
    "    #print(total_words)\n",
    "    \n",
    "    edit_dist = [edit_distance(text,w,transpositions=True) for w in total_words]\n",
    "    \n",
    "    #print(jaccard_dist)\n",
    "    \n",
    "    min_dist = min(edit_dist)\n",
    "    \n",
    "    ans3.append(total_words[edit_dist.index(min_dist)])\n",
    "    \n",
    "    return ans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mano']\n",
      "['validate']\n",
      "['intendence']\n",
      "['corpulent']\n",
      "['spelling']\n",
      "['recommender']\n"
     ]
    }
   ],
   "source": [
    "text = ['meano','validrate','incendenece','cormulent','spleling','reccomender']\n",
    "\n",
    "for t in text:\n",
    "    print(Model_3(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
